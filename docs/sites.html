<html>
<head>
  <title>BISICLES site specific notes</title> 
  <link href="bikedoc.css" rel="stylesheet" type="text/css"/>
</head>
<body>

<div id="head">
<ul>
<li><a href='index.html'>Index page<a/> </li>
<li><a href='#top'>Top of page<a/> </li>
</ul>

<h1>Contents</h1>

<ol>
  <li><a href='#debian'>Debian based systems (e.g Ubuntu) </a></li>
  <li><a href='#uob'>University of Bristol</a></li>
  <li><a href='#nersc'>NERSC</a></li>
  <li><a href='#archer'>ARCHER (Cray XC30,</li>
  <li><a href='#monsoon'>UKMO Monsoon (Cray XC40)</a></li>
  <li><a href='#hpcwales'>HPC Wales (Swansea University) </a></li>
  <li><a href='#monsoonaix'>UKMO Monsoon (AIX, defunct)</li>
</ol>
</div>


<div id="main">
<h1><a name='top'>BISICLES site specific notes</a></h1>

<h2><a name='debian'>Debian based systems (e.g Ubuntu)</a></h2>

<p>
  Recent Debian GNU/Linux derivatives (from around 2016), including Ubuntu 16.04 and 16.10, allow an mpi environment ,
  hdf5, and netcdf to be installed in a way that works well for BISICLES. On Ubuntu 16.xx, run
</p>
<pre>
  sudo apt-get install csh mpi-default-bin mpi-default-dev libhdf5-mpi-dev libhdf5-dev hdf5-tools libnetcdff-dev libnetcdf-dev
</pre>
<p>
  The file $BISICLES_HOME/Chombo/lib/mk/Make.defs.local should contain:
</p>
<pre>
PRECISION     = DOUBLE  
CXX           = g++
FC            = gfortran
MPICXX        = mpiCC
USE_HDF       = TRUE
HDFINCFLAGS   = -I/usr/include/hdf5/serial/
HDFLIBFLAGS   = -L/usr/lib/x86_64-linux-gnu/hdf5/serial/ -lhdf5 -lz
HDFMPIINCFLAGS= -I/usr/include/hdf5/openmpi/ 
HDFMPILIBFLAGS= -L/usr/lib/x86_64-linux-gnu/hdf5/openmpi/ -lhdf5  -lz
cxxdbgflags    = -g -fPIC 
cxxoptflags    = -fPIC -O2
fdbgflags     =  -g -fPIC 
foptflags     = -fPIC -O3 -ffast-math -funroll-loops 
</pre>
<p>
  and the file $BISICLES_HOME/BISICLES/code/mk/Make.defs.$mymachine (where $mymachine is
  the output from 'uname -n') should contain
</p>
<pre>
NETCDF_HOME=$(shell nc-config --prefix)
NETCDF_LIBS=-lnetcdff -lnetcdf -lhdf5_hl
PYTHON_VERSION=2.7
</pre>


<h2><a name='uob'>University of Bristol</a>

<h3>Blue Crystal Phase 3</h3>

<h4>Blue Crystal Phase 3, GNU Compilers</h4>
<p>
To use the GNU compilers on Blue Crystal Phase 3, include
</p>
<pre>
module load languages/gcc-4.8.1
module load openmpi/gcc/64/1.6.5
module load languages/python-2.7.5
</pre>
<p>
in .bash_profile. There are ready-made Make.defs.newblue files
that work with the python install, but hdf5 (and netcdf) need to
be built as described in the <a href='readme.html'>generic instructions</a>.

<h4>Blue Crystal Phase 3, Intel Compilers</h4>
<p>
To use the Intel compilers on Blue Crystal Phase 3, include
</p>
<pre>
module load intel-cluster-studio/impi/64
module load intel-cluster-studio/compiler/64
module load openmpi/intel/64
module load languages/python-2.7.5
</pre>
<p>
in .bash_profile. There are ready-made Make.defs.newblue files
that work with the python install, but hdf5 (and netcdf) need to
be built as described in the <a href='readme.html'>generic instructions</a>.

<h2><a name='nersc'>NERSC</a></h2>
The US DOE-run National Energy Research Supercomputing Center ( <a href='http://www.nersc.gov'>NERSC</a>) has several machines which BISICLES users may find useful. 

<h3>Edison -- GNU compilers</h3>

<p>
  The Cray XC30 (Edison) at NERSC offers Cray, GNU, and Intel compilers. All three compilers can be supported with a single
  Make.defs.local, it only only necessary to load the correct PrgEnv module and the cray-hdf5-parallel.
</p>

<p>
  To compile with GNU, switch to the correct PrgEnv and load an hdf5 module, plus netcdf and python if desired
</p>
<pre>
> module swap PrgEnv-intel PrgEnv-gnu
> module load cray-hdf5-parallel
> module load python
> module load cray-netcdf-hdf5parallel
> module unload module unload cray-shmem #needed for python only
</pre>
<p>
  To have the python interface work, the compiler needs the -shared and -fPIC flags, and
  the linker needs the -dynamic flag. An example $BISICLES_HOME/Chombo/lib/mk/local/Make.defs.local would be:
</p>
<pre>
makefiles+=Make.defs.local

#default to MPI=TRUE,OPT=TRUE,DEBUG=FALSE 
MPI=TRUE
OPT=TRUE
DEBUG=FALSE

#this seems to be the Cray way
CXX=CC
FC=ftn
MPICXX=CC
USE_64=TRUE

ifeq ($(PE_ENV),GNU)

CH_CPP=$(CXX) -E -P -C
XTRACONFIG=.GNU
cxxoptflags += -shared -fPIC
foptflags += -shared -fPIC
ldoptflags += -dynamic
cxxoptflags += -march=ivybridge -O2 -mavx -ftree-vectorize -ffast-math -funroll-loops
foptflags += -march=ivybridge -O2 -mavx -ftree-vectorize -ffast-math -funroll-loops

else
$(ECHO) "UNKNOWN PROGRAMMING ENVIRONMENT!"
endif

# The appropriate module (cray-hdf5-parallel) must be loaded for this to work.
USE_HDF=TRUE
HDFLIBFLAGS=   -L$(HDF5_DIR)/lib     $(HDF_POST_LINK_OPTS)  -lhdf5 -lz
HDFMPILIBFLAGS=-L$(HDF5_DIR)/lib     $(HDF_POST_LINK_OPTS)  -lhdf5 -lz
HDFINCFLAGS=   -I$(HDF5_DIR)/include $(HDF_INCLUDE_OPTS)
HDFMPIINCFLAGS=-I$(HDF5_DIR)/include $(HDF_INCLUDE_OPTS)
</pre>

<p>
  For python and netcdf, $BISICLES_HOME/BISICLES/code/mk/Make.defs.edison should include:
</p>
<pre>
PYTHON_INC=/usr/common/usg/python/2.7.9/include/python2.7
PYTHON_LIBS=-L/usr/common/usg/python/2.7.9/lib/ -lpython2.7 -ldl -lutil -lm -Xlinker -export-dynamic
NETCDF_INC=$(shell nc-config --includedir)
NETCDF_LIBS=$(shell nc-config --flibs)
</pre>
  
<h3>Hopper -- GNU compilers</h3>

The admiral has now been dismantled, and it was pretty similar to another Cray, <a href='#archer'>ARCHER</a>,
so we will say no more.

<h2><a name='archer'>ARCHER</a></h2>

<p>
The Cray XC30 at ARCHER (UK National HPC) offers Cray, GNU, and Intel compilers.
Cray is the default (but doesn't seem to work for now). All three compilers can be supported with a single
Make.def.locals, it only only necessary to load the correct PrgEnv module and the cray-hdf5-parallel. 
Use the file Make.defs.archer included with Chombo
</p>
<pre>
ln -s $BISICLES_HOME/Chombo/lib/mk/local/Make.defs.archer $BISICLES_HOME/Chombo/lib/mk/Make.defs.local
</pre>

<h3>ARCHER -- GNU compilers </h3>
<p>
To compile with GNU, switch to the correct PrgEnv and load an hdf5 module
</p>
<pre>
> module swap PrgEnv-cray PrgEnv-gnu
> module load cray-hdf5-parallel
> module load python-compute
> module load cray-netcdf-hdf5parallel
> module unload module unload cray-shmem # need this for dynamic linking
</pre>

<p>
$BISICLES_HOME/BISICLES/code/mk/Make.defs.archer
includes the following details for the python interface
and netcdf. Copy this file to Make.defs.none or Make.defs.$UNAMEN
(where $UNAMEN is the output from uname -n)
</p>
<pre>   

</pre>
<p>
Then compile 
</p>
<pre>
cd BISICLES/code/exec2D
make all OPT=TRUE MPI=TRUE DEBUG=FALSE # are all default 
</pre>
<p>
the exectable will be driver2d.Linux.64.CC.ftn.OPT.MPI.GNU.ex
</p>

<p> ARCHER's compute nodes do not have access to the /home mount point (and therefore your home directory) 
It's not obvious where login scripts come from in that case, either. This can all be dealt with inside the submission script
(the MOM nodes do have access to home...). A minimal script (run from somewhere in /work) would look something like
<pre>
#PBS -l walltime=00:10:00 
#PBS -j oe 
#PBS -l select=1
#PBS -A /your allocation/  

export PBS_O_WORKDIR=$(readlink -f $PBS_O_WORKDIR)

#load modules needed to get GLIBCXX, HDF5, python where the compute nodes can see them
module swap PrgEnv-cray PrgEnv-gnu
module load cray-hdf5-parallel
module load python-compute

cd $PBS_O_WORKDIR

EXE=/path/to/driver2d.Linux.64.CC.ftn.OPT.MPI.GNU.ex 
aprun -n 24 $EXE inputs.whatever
</pre>


<h3>ARCHER - Intel compilers </h3>

Compiling with Intel is essentially the same as with GNU. It's just a case of running
<pre>
> module swap PrgEnv-cray PrgEnv-intel
> module load cray-hdf5-parallel 
</pre>
instead of
<pre>
> module swap PrgEnv-cray PrgEnv-gnu
> module load cray-hdf5-parallel 
</pre>
The binary will be called driver2d.Linux.64.CC.ftn.OPT.MPI.INTEL.ex. Just as with GNU, 
the submission scripts needs to account for the fact that /home is not visible
on the compute nodes.

<h2><a name='monsoon'>The Monsoon Cray XC40 at the UK Met Office</a></h2>
<p>
  The Monsoon Cray XC40 is much like ARCHER (and eidison and cori at NERSC).
  So much so that the ARCHER makefile seems to work, ie
</p>
<pre>
ln -s $BISICLES_HOME/Chombo/lib/mk/local/Make.defs.archer $BISICLES_HOME/Chombo/lib/mk/Make.defs.local
</pre>
<p>
  I'm assuming that Monsoon users are interested in bisicles coupled via glimmer-cism to
  UKESM, i.e have checked out UniCiCles, and want to use the intel compiler. 
</p>
<pre>
> module swap PrgEnv-cray PrgEnv-intel
> module load cray-hdf5-parallel
> module load python/v2.7.9 #optional, needed if you want the python interface
> module load cray-netcdf-hdf5parallel #optional, needed if you want glimmer-cism 
> module load cray-tpsl/1.5.2 #optional, needed if you want the petsc solver
> module load cray-petsc/3.6.1.0 #optional, needed if you want the petsc solver
</pre>
<p>
If you want the python interface, make sure that  $BISICLES_HOME/BISICLES/code/mk/Make.defs includes 
the following
</p>
<pre>      
PYTHON_DIR=opt/python/gnu/2.7.9                                                                                    
PYTHON_INC=$(PYTHON_DIR)/include/python2.7                                                                        
PYTHON_LIBS=-L$(PYTHON_DIR)/lib -lpython2.7                                                            
</pre>
<p>
and for netcdf stuff (e.g glimmer-cism, filetoools)
</p>
NETCDF_INC=$(NETCDF_DIR)/include  
NETCDF_LIBS=-L$(NETCDF_DIR)/lib -lnetcdf
<p>
Compile with
</p>
<pre>
cd BISICLES/code/exec2D
make all OPT=TRUE MPI=TRUE DEBUG=FALSE # are all default 
</pre>
<op>
The binary will be called driver2d.Linux.64.CC.ftn.OPT.MPI.INTEL.ex
</p>
<p>
Or, with the PETSC interface
</p>
<pre>
cd BISICLES/code/exec2D
make all OPT=TRUE MPI=TRUE DEBUG=FALSE USE_PETSC=TRUE
</pre>
<op>
The binary will be called driver2d.Linux.64.CC.ftn.OPT.MPI.PETSC.INTEL.ex
</p>

<h2><a name='hpcwales'>HPC Wales (Swansea University)</a></h2>
<p>
  HPC Wales providea number of clusters, including two at Swansea University. To login to the Swansea
  systems, first login to the HPC Wales login node, then a Swansea login node, e.g
</p>
<pre>
  ssh user.name@login.HPCWales.co.uk
  ssh ssl001
</pre>
<p>
  To use subversion (svn), we need to setup a proxy for http/https. There
  is an http-proxy module, but subversion ignores the environment variable it sets.
  However, it can be used to see what the proxy should be. e.g
</p>
<pre>
>module show http-proxy
-------------------------------------------------------------------
/app/modules/system/http-proxy:

module-whatis	 set http proxy environment variables 
setenv		 http_proxy http://10.211.143.6:8080 
setenv		 https_proxy http://10.211.143.6:8080 
setenv		 ftp_proxy http://10.211.143.6:8080 
setenv		 all_proxy http://10.211.143.6:8080 
---------------------------------------------------------
</pre>
<p>
and then edit $HOME/subversion/servers to include    
</p>
<pre>
http-proxy-host = 10.211.143.6
http-proxy-port = 8080
</pre>

<p>
Although hdf5 etc are provided, there are only a few valid combinations of compiler, mpi, hdf5, python etc. We will assume GNU 4.8.0 with openmpi 1.8.5:
</p>
<pre>
module load subversion
module load compiler/gnu/4.8.0
module load mpi/openmpi/1.8.5
module load hdf5/1.8.13
module load python/2.7.9
module load petsc
</pre>


<h2><a name='monsoonaix'>The Monsoon AIX machine at the UK Met Office</a></h2>
<strong>Monsoon has been replaced with a Cray (descibed above) The instructions below are left just in case anyone trying to work with a similar system </strong>
<p>
Monsoon is an IBM AIX  system with the xl compilers installed. It is somewhat more
awkward to build with than the other clusters described: the xlf FORTRAN compiler doesn't distuingish between f77 and
f90 code  by the file extension, make is not GNU make (so use gmake instead) and
it is not possible to run mpi compiled jobs on the login nodes so that, for example, it is necessary to
create job submission scripts to configure parallel hdf5 (which is not installed on the system as of 17 Feb 2014)
</p>
<p>
ksh is the default shell. Whichever shell is used, 
it is necessary to somehow run 
<pre>
. prg_14_1_0_6
module load autotools/20131210
</pre>
Make.defs.local should contains:
<pre>
OPT           = TRUE
PRECISION     = DOUBLE
CXX           = xlC
FC            = xlf
MPI           = TRUE
MPICXX        = mpCC_r
USE_64        = TRUE
USE_HDF       = TRUE
#make sure BISICLES_HOME is correct
BISICLES_HOME=wherever/that/is
#make sure HDF_DIR is correct
HDFDIR=$(BISICLES_HOME)/hdf5/parallel
HDFINCFLAGS   = -I$(HDFDIR)/include -DH5_USE_16_API 
HDFLIBFLAGS   = -L$(HDFDIR)/lib -lhdf5 -lz
## Note: don't set the HDFMPI* variables if you don't have parallel HDF installed
HDFMPIINCFLAGS= -I$(HDFDIR)/include  -DH5_USE_16_API 
HDFMPILIBFLAGS= -L$(HDFDIR)/lib -lhdf5 -lz
syslibflags   = -L /critical/opt/lapack/3.4.0/lib/ -llapack_aix64_ -lblas_aix64_
</pre>

<p>
Attemping to configure and build hdf5 on the login node will fail, and a submission script is needed. 
</p>
<pre>
#!/bin/bash
#
# attempt to submit hdf5 parallel configure to a compute node.              
# This is necessary because jobs compiled with mpcc_r refuse
# to run on the login node...

#@ shell            = /usr/bin/bash
#@ class            = parallel
#@ job_type        = parallel
#@ job_name         = hdf5_parallel_configure
#@ output          = $(job_name).$(jobid).out
#@ error           = $(job_name).$(jobid).out
#@ node = 1
#@ tasks_per_node = 1
#@ notification     = error
#@ resources        = ConsumableCpus(1) ConsumableMemory(200mb)
#@ cpu_limit        = 00:10:00
#@ wall_clock_limit = 00:15:00
#@ queue

#This approved method doesn't seem to work...
#. prg_14_1_0_6
#module load autotools/20131210

PATH=/critical/opt/autotools/20131210/bin:/critical/opt/vacpp/v11.1.0.5/usr/vacpp/bin:/critical/opt/xlf/v14.1.0.6/usr/bin:/critical/opt/ukmo/mass/moose-monsoon-client-latest/bin:/opt/\
ibmhpc/pecurrent/ppe.poe/bin/:/usr/bin:/etc:/usr/sbin:/usr/bin/X11:/sbin:/usr/java5/jre/bin:/usr/java5/bin:/critical/opt/ukmo/supported/bin:/critical/opt/ukmo/freeware/bin:/opt/freewa\
re/bin

cd /home/slcorn/model/hdf5/parallel
CC=mpcc_r  AR="ar -X 64" ../hdf5-1.8.9/configure --prefix=/home/slcorn/model/hdf5/parallel --enable-shared=no
gmake
gmake install
exit 0
#End of script : submit with llsubmit 
</pre>


Steph also had to modify Chombo/lib/mk/compiler/Make.defs.IBM, Chombo/lib/mk/compiler/Make.rules:
xlf does not select free or fixed format code based on the file extension, and we have
relies on that feature up till now. There also seems to be something in the way that xlC 
handles class templates that meant modifications were needed to Chombo/lib/src/AMRElliptic/PetscSolver.H and PetscSolverI.H 
Diffs below, alternately contact steph (s.l.cornford@bristol.ac.uk) for the relevant files until 
either Chombo gets changed or we work something better out.
<pre>

bash-4.2$ svn diff ../../../Chombo/lib/mk/Make.rules            
Index: ../../../Chombo/lib/mk/Make.rules
===================================================================
--- ../../../Chombo/lib/mk/Make.rules   (revision 21511)
+++ ../../../Chombo/lib/mk/Make.rules   (working copy)
@@ -435,7 +435,7 @@
 
 
 o/$(config)/%.o : %.f90  d/$(config)/%.d
-       $(QUIET)$(FC) $(FFLAGS) $(XTRAFFLAGS) $(fcompflag) $< $(fobjflag)$@
+       $(QUIET)$(FC) $(F90FLAGS) $(FFLAGS) $(XTRAFFLAGS) $(fcompflag) $< $(fobjflag)$@
 
 
 o/$(config)/%.o : %.ChF  d/$(config)/%.d
@@ -446,15 +446,15 @@
 
 o/$(config)/%.o : %.F  d/$(config)/%.d
        $(QUIET)$(CSHELLCMD) "$(CH_CPP) $(CPPFLAGS) $(XTRACPPFLAGS) $(fcppflags) -DCH_LANG_FORT $< | $(fortpost) | awk 'NF>0' > f/$(config)/$*.f"
-       $(QUIET)$(FC) $(FFLAGS) $(XTRAFFLAGS) $(fcompflag) f/$(config)/$*.f $(fobjflag)$@
+       $(QUIET)$(FC) $(F77FLAGS) $(FFLAGS) $(XTRAFFLAGS) $(fcompflag) f/$(config)/$*.f $(fobjflag)$@
 
 o/$(config)/%.o : %.F90  d/$(config)/%.d
        $(QUIET)$(CSHELLCMD) "$(CPP) $(CPPFLAGS) $(XTRACPPFLAGS) $(fcppflags) -DCH_LANG_FORT $< | $(fortpost) | awk 'NF>0' > f/$(config)/$*.f90"
-       $(QUIET)$(FC) $(FFLAGS) $(XTRAFFLAGS) $(fcompflag) f/$(config)/$*.f90 $(fobjflag)$@
+       $(QUIET)$(FC) $(F90FLAGS) $(FFLAGS) $(XTRAFFLAGS) $(fcompflag) f/$(config)/$*.f90 $(fobjflag)$@
 
 
 o/$(config)/%.o : %.f  d/$(config)/%.d
-       $(QUIET)$(FC) $(FFLAGS) $(XTRAFFLAGS) $(fcompflag) $< $(fobjflag)$@
+       $(QUIET)$(FC) $(F77FLAGS) $(FFLAGS) $(XTRAFFLAGS) $(fcompflag) $< $(fobjflag)$@
 
 ##
 ## Rules to build ChomboFortran header files


bash-4.2$  svn diff ../../../Chombo/lib/mk/compiler/Make.defs.IBM
Index: ../../../Chombo/lib/mk/compiler/Make.defs.IBM
===================================================================
--- ../../../Chombo/lib/mk/compiler/Make.defs.IBM       (revision 21511)
+++ ../../../Chombo/lib/mk/compiler/Make.defs.IBM       (working copy)
@@ -50,8 +50,11 @@
     # -qtune will by default take on the value of -qarch (ndk)
     # -qstrict is strongly recommended to prevent the compiler from messing up the code <dbs>
     # -qsuppress suppresses messages: 1091 complains about friend declarations
-    # -qsuppress suppresses messages: 2907 complains about array bounds-checking    
-    defcxxcomflags = -qsuppress=1540-1091 -qsuppress=1540-2907 -qrtti=dynamiccast
+    # -qsuppress suppresses messages: 2907 complains about array bounds-checking
+    # 2704 complains about declarations     
+    F77FLAGS=-qfixed
+    F90FLAGS=-qfree
+    defcxxcomflags = -qsuppress=1540-1091 -qsuppress=1540-2907 -qsuppress=1540-0274 -qrtti=dynamiccast
     defcxxoptflags = -O3 -qstrict -qarch=auto # -qstaticinline -qinlglue -qlargepage
     defcxxdbgflags = -g -qflttrap -qfullpath -qdbxextra -qcheck=nullptr -qstatsym
 
@@ -73,14 +76,9 @@
     # xl* compile uses "-P" for output to file, so don't use it.
     # -C disables stripping "//" comments because they are valid Fortran code
     # -qsuppress suppresses messages: 234 complains about "0.0D0" float constants
-    ifeq ($(_xlcmajorver),8)
-      CH_CPP = $(CXX) -E -C -qnoppline -qsourcetype=c -qsuppress=1506-234
-    else ifeq ($(_xlcmajorver),10) # for bluefire.ucar.edu (DFM - 4/14/11)
-      CH_CPP = $(CXX) -E -C -qnoppline -qsourcetype=c -qsuppress=1506-234
-    else
-      CH_CPP = $(CXX) -E -C
-    endif
 
+      CH_CPP = $(CXX) -E -C -qnoppline -qsourcetype=c -qsuppress=1540-829
+
     # xlC appears to be OK with MT again...
     USE_MT = TRUE
   endif
@@ -102,7 +100,7 @@
     # -qstrict makes sure the compiler optimizer doesn't change the results <dbs>
     # -qsuppress suppresses messages: 510 is the "compilation successful" msg
     deffcomflags = -qsuppress=1501-510
-    deffoptflags = -O3 -qarch=auto -qfixed -qmaxmem=99999 -qhot -qstrict
+    deffoptflags = -O3 -qarch=auto  -qmaxmem=99999 -qhot -qstrict
     deffdbgflags = -g -C -qfullpath # -qextchk
     deffprofflags = -pg
     ifneq ($(USE_EXTNAME),FALSE)


bash-4.2$  svn diff ../../../Chombo/lib/src/AMRElliptic/PetscSolver.H
Index: ../../../Chombo/lib/src/AMRElliptic/PetscSolver.H
===================================================================
--- ../../../Chombo/lib/src/AMRElliptic/PetscSolver.H   (revision 21511)
+++ ../../../Chombo/lib/src/AMRElliptic/PetscSolver.H   (working copy)
@@ -269,10 +269,10 @@
 
 #include "NamespaceFooter.H"
 
-#ifdef CH_USE_PETSC
+//#ifdef CH_USE_PETSC
 #ifndef CH_EXPLICIT_TEMPLATES
 #include "PetscSolverI.H"
 #endif // CH_EXPLICIT_TEMPLATES
-#endif
+//#endif
 
 #endif /*_PETSCSOLVER_H_*/

../../Chombo/lib/src/AMRElliptic/PetscSolverI.H
===================================================================
--- ../../../Chombo/lib/src/AMRElliptic/PetscSolverI.H  (revision 21511)
+++ ../../../Chombo/lib/src/AMRElliptic/PetscSolverI.H  (working copy)
@@ -18,14 +18,17 @@
 #include "memusage.H"
 #include "NamespaceHeader.H"
 
+#ifdef CH_USE_PETSC
 #include <private/kspimpl.h>   /*I "petscksp.h" I*/
 #include <private/pcimpl.h>
+#endif
 
 // *******************************************************
 // PetscSolver Implementation
 // *******************************************************
 template <class T>
 PetscSolver<T>::PetscSolver()
+#ifdef CH_USE_PETSC
   :m_homogeneous(false),
    m_mat(0), // m_xx, m_rr, m_bb;
    m_ksp(0),
@@ -36,6 +39,7 @@
    m_null(false),
    m_nz_init_guess(false),
    m_gid0(0)
+#endif
 {
   m_dx = 0.;
 }
@@ -43,16 +47,18 @@
 template <class T>
 void PetscSolver<T>::destroy()
 {
+#ifdef CH_USE_PETSC
   if ( m_defined )
   {
-#ifdef CH_USE_PETSC
+
     MatDestroy(&m_mat);
     VecDestroy(&m_bb);
     VecDestroy(&m_xx);
     VecDestroy(&m_rr);
-#endif
     m_defined = 0;
+
   }
+#endif
 #ifdef CH_USE_PETSC
   if ( m_ksp )
     {

</pre>
</div>
</body>
</html>
